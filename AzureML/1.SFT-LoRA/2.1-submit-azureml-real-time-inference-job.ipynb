{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71367717-76ef-49f3-9fc0-2826b165adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import logging\n",
    "import yaml\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Environment, ManagedOnlineDeployment, ManagedOnlineEndpoint, CodeConfiguration\n",
    "from azure.identity import DefaultAzureCredential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e95a27e-a1be-4209-8a57-42c01b8892eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to log in to Azure\n",
    "#!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b673b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global logging level\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# Specifically reduce Azure-related logging in this notebook\n",
    "logging.getLogger(\"azure\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"azure.identity\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"azure.core.pipeline.policies.http_logging_policy\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1667f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Azure ML workspace configuration from config.yml\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Azure ML workspace configuration\n",
    "subscription_id = config[\"subscription_id\"]\n",
    "resource_group = config[\"resource_group\"]\n",
    "workspace_name = config[\"workspace_name\"]\n",
    "\n",
    "# finetuned model configuration\n",
    "finetuned_model_name = config[\"finetuned_model_name\"]\n",
    "finetuned_model_version = config[\"finetuned_model_version\"]\n",
    "\n",
    "# inference environment configuration\n",
    "inference_env_name = config[\"inference_env_name\"]\n",
    "inference_env_version = config[\"inference_env_version\"]\n",
    "inference_env_description = config[\"inference_env_description\"]\n",
    "inference_env_conda_file = config[\"inference_env_conda_file\"]\n",
    "inference_env_base_image = config[\"inference_env_base_image\"]\n",
    "\n",
    "# finetuned model real-time endpoint configuration\n",
    "endpoint_name = config[\"endpoint_name\"]\n",
    "deployment_name = config[\"deployment_name\"]\n",
    "deployment_instance_type = config[\"deployment_instance_type\"]\n",
    "deployment_instance_count = config[\"deployment_instance_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3d4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ML Client\n",
    "ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474596ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the registered model ID from previous notebook that can be used for deployment.\n",
    "registered_model = ml_client.models.get(name=finetuned_model_name, version=finetuned_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c40fd4-330f-48df-b536-63dea7118965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing environment: finetuned-phi4-model-env:4\n"
     ]
    }
   ],
   "source": [
    "# Create or get inference environment\n",
    "try:\n",
    "    # Try to get existing environment\n",
    "    env_asset = ml_client.environments.get(name=inference_env_name, version=inference_env_version)\n",
    "    print(f\"Using existing environment: {inference_env_name}:{inference_env_version}\")\n",
    "except:\n",
    "    # Create new environment if it doesn't exist\n",
    "    print(f\"Creating new environment: {inference_env_name}\")\n",
    "    env_asset = Environment(\n",
    "        name=inference_env_name,\n",
    "        conda_file=inference_env_conda_file,\n",
    "        image=inference_env_base_image,\n",
    "        description=\"Environment for realtime inference with fine-tuned model\"\n",
    "    )\n",
    "    env_asset = ml_client.environments.create_or_update(env_asset)\n",
    "    print(f\"Environment created: {env_asset.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e357351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new endpoint: ft-phi4-mini-instruct-endpoint\n",
      "Endpoint 'ft-phi4-mini-instruct-endpoint' created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create the endpoint\n",
    "try:\n",
    "    # Try to get existing endpoint\n",
    "    endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "    print(f\"Using existing endpoint: {endpoint_name}\")\n",
    "except:\n",
    "    print(f\"Creating new endpoint: {endpoint_name}\")\n",
    "    \n",
    "    # Create the end point\n",
    "    endpoint = ManagedOnlineEndpoint(\n",
    "        name=endpoint_name,\n",
    "        auth_mode=\"key\",\n",
    "        description=\"Endpoint for fine-tuned model inference\"\n",
    "    )\n",
    "    endpoint = ml_client.begin_create_or_update(endpoint).result()\n",
    "    print(f\"Endpoint '{endpoint_name}' created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05454abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    }
   ],
   "source": [
    "# Delete the endpoint in case of any issues and retry creating it\n",
    "# ml_client.online_endpoints.begin_delete(name=endpoint_name).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abed4f7-1e87-47a6-b51e-d83bfc27439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint ft-phi4-mini-instruct-endpoint exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new deployment: blue\n",
      "Creating deployment... This may take several minutes.\n",
      ".......................................................................................................Deployment 'blue' created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create deployment for the endpoint\n",
    "try:\n",
    "    # Try to get existing deployment\n",
    "    deployment = ml_client.online_deployments.get(deployment_name, endpoint_name)\n",
    "    print(f\"Using existing deployment: {deployment_name}\")\n",
    "except:\n",
    "    print(f\"Creating new deployment: {deployment_name}\")\n",
    "    deployment = ManagedOnlineDeployment(\n",
    "        name=deployment_name,\n",
    "        endpoint_name=endpoint_name,\n",
    "        model=registered_model.id,\n",
    "        environment=env_asset.id,\n",
    "        code_configuration=CodeConfiguration(code=\"./serve\", scoring_script=\"score_real_time.py\"),\n",
    "        instance_type=deployment_instance_type,\n",
    "        instance_count=deployment_instance_count\n",
    "    )\n",
    "\n",
    "    print(\"Creating deployment... This may take several minutes.\")\n",
    "    deployment = ml_client.begin_create_or_update(deployment).result()\n",
    "    print(f\"Deployment '{deployment_name}' created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cf7cb-1687-4318-b654-cef878c24d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set traffic to deployment\n",
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57f57f",
   "metadata": {},
   "source": [
    "## Testing the real-time end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcd7b201-27fe-4311-8956-f2a949b551c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content = \"\"\"\n",
    "Question:\n",
    "A 21-year-old sexually active male complains of fever, pain during urination, and inflammation and pain in the right knee. A culture of the joint fluid shows a bacteria that does not ferment maltose and has no polysaccharide capsule. The physician orders antibiotic therapy for the patient. The mechanism of action of action of the medication given blocks cell wall synthesis, which of the following was given?\n",
    "            \n",
    "Options:\n",
    "A. Chloramphenicol\n",
    "B. Gentamicin\n",
    "C. Ciprofloxacin\n",
    "D. Ceftriaxone\n",
    "E. Trimethoprim\"\"\"\n",
    "\n",
    "sample = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a medical expert. Read the following USMLE question and choose the best answer. Just give the option.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_new_tokens\": 10,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30ff9a17-01ec-47f5-a455-b6ac09553af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"request.json\", \"w\") as f:\n",
    "    json.dump(sample, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5050661b-215b-4dad-b1b2-1551c87e9a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C\"\n"
     ]
    }
   ],
   "source": [
    "response = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    request_file=\"request.json\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51dc78",
   "metadata": {},
   "source": [
    "### Make sure to delete the clusters (dedicated ones) and endpoints after evaluation. Low-priority clusters scale to 0 automatically, so they don't incur costs when idle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a5024",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
